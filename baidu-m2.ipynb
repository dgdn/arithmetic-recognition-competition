{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 760 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "path = \"data/baidu/\"\n",
    "#path = \"data/state/sample/\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = gen.flow_from_directory(path+'/image_contest_level_1', \n",
    "                                  batch_size=1, \n",
    "                                  target_size=(30,90),\n",
    "                                  shuffle=False,\n",
    "                                  class_mode=None,\n",
    "                                  color_mode='grayscale'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.concatenate([batches.next() for i in range(batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(path+'imgs.dat', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = load_array(path+'imgs.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2label_idx = [int(f[8:][:-4]) for f in batches.filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81314, 42703, 94273, 72552, 17141, 50750, 48773, 94926, 47470, 13306]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2label_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_texts = []\n",
    "lines = []\n",
    "with open(path+'labels.txt') as f:\n",
    "    lines = f.readlines()\n",
    "label_texts = [l.strip().split()[0] for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(4*8)+8',\n",
       " '7+3*0',\n",
       " '5+(5+2)',\n",
       " '(8-0)-8',\n",
       " '0+(0+2)',\n",
       " '(2*5)+0',\n",
       " '0+(1+8)',\n",
       " '2+(4+9)',\n",
       " '7*2+4',\n",
       " '0-(7*1)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = ['0','1','2', '3','4','5','6','7','8','9', \n",
    "          '+', '-', '*',\n",
    "         '(0', '(1', '(2', '(3', '(4', '(5', '(6', '(7', '(8', '(9',\n",
    "         '0)', '1)', '2)', '3)', '4)', '5)', '6)', '7)', '8)', '9)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2idx={char:i for i, char in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for ts in label_texts:\n",
    "    cursor = 0\n",
    "    l = []\n",
    "    while cursor < len(ts):\n",
    "        c = ts[cursor]\n",
    "        if c == '(':\n",
    "            l.append(token2idx[c + ts[cursor+1]])\n",
    "            cursor = cursor + 2\n",
    "        elif cursor+1 < len(ts) and ts[cursor+1] == ')':\n",
    "            l.append(token2idx[c + ts[cursor+1]])\n",
    "            cursor = cursor + 2\n",
    "        else:\n",
    "            l.append(token2idx[c])\n",
    "            cursor = cursor + 1\n",
    "\n",
    "    labels.append(l)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_size, seq_len = len(tokens), len(labels[0])\n",
    "token_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.permutation(imgs.shape[0])\n",
    "mask = np.random.rand(len(imgs)) < 0.8\n",
    "trn_idxs = idxs[mask]\n",
    "val_idxs = idxs[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80044, 19956)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_idxs), len(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_trn = imgs[trn_idxs]\n",
    "y_trn_m = labels[np.array(x2label_idx)[trn_idxs]]\n",
    "\n",
    "y_trn = np.expand_dims(np.stack(y_trn_m, axis=0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80044, 1, 30, 90), (80044, 5, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn.shape, y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80044, 5, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = imgs[val_idxs]\n",
    "y_val_m = labels[np.array(x2label_idx)[val_idxs]]\n",
    "y_val = np.expand_dims(np.stack(y_val_m, axis=0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19956, 1, 30, 90), (19956, 5, 1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1+4+8NN'], \n",
       "      dtype='|S7')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label_texts)[np.array(x2label_idx)[[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAECCAYAAAAb0NrOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nALnFyTAAAAByi5NhAAAA5Nb/Byv3+fdV/IhdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8f33c8c5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots([image.load_img(path + 'image_contest_level_1/'+batches.filenames[13419])], titles=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-(8+4)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idxs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = x_trn.mean().astype(np.float32)\n",
    "std_px = x_trn.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viiv/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_15 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 60, 180)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,60,180)),\n",
    "    Flatten(),\n",
    "    Dense(70, activation='relu'),\n",
    "    Reshape((7, 10)),\n",
    "    TimeDistributed(Dense(17, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_15 (Lambda)               (None, 1, 60, 180)    0           lambda_input_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 10800)         0           lambda_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 70)            756070      flatten_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)             (None, 7, 10)         0           dense_32[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_14 (TimeDistribu (None, 7, 17)         187         reshape_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 756,257\n",
      "Trainable params: 756,257\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7939 samples, validate on 2061 samples\n",
      "Epoch 1/1\n",
      "7939/7939 [==============================] - 1s - loss: 0.9430 - acc: 0.6604 - val_loss: 1.0708 - val_acc: 0.6259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36aaddc950>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Vgg style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viiv/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_16 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 60, 180)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,30,90)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(seq_len*10, activation='relu'),\n",
    "    Reshape((seq_len, 10)),\n",
    "    TimeDistributed(Dense(token_size, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7939 samples, validate on 2061 samples\n",
      "Epoch 1/2\n",
      "7939/7939 [==============================] - 28s - loss: 1.7933 - acc: 0.3787 - val_loss: 1.4461 - val_acc: 0.5168\n",
      "Epoch 2/2\n",
      "7939/7939 [==============================] - 28s - loss: 1.2494 - acc: 0.5891 - val_loss: 1.1649 - val_acc: 0.6127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3697c46890>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7939 samples, validate on 2061 samples\n",
      "Epoch 1/2\n",
      "7939/7939 [==============================] - 28s - loss: 1.0651 - acc: 0.6478 - val_loss: 1.0614 - val_acc: 0.6546\n",
      "Epoch 2/2\n",
      "7939/7939 [==============================] - 28s - loss: 0.9381 - acc: 0.6866 - val_loss: 0.9928 - val_acc: 0.6744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3697c46b50>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7939 samples, validate on 2061 samples\n",
      "Epoch 1/2\n",
      "7939/7939 [==============================] - 28s - loss: 0.8705 - acc: 0.7040 - val_loss: 0.9370 - val_acc: 0.6873\n",
      "Epoch 2/2\n",
      "7939/7939 [==============================] - 28s - loss: 0.8052 - acc: 0.7193 - val_loss: 0.9007 - val_acc: 0.6938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3697c46b10>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viiv/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 30, 90)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,30,90)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(seq_len*20, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Reshape((seq_len, 20)),\n",
    "    TimeDistributed(Dense(token_size, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 1, 30, 90)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 28, 88)    320         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 32, 28, 88)    128         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 26, 86)    9248        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 32, 26, 86)    128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 13, 43)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 11, 41)    18496       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 64, 11, 41)    256         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 64, 9, 39)     36928       batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 64, 9, 39)     256         convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 4, 19)     0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 4864)          0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 4864)          19456       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 50)            243250      batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 50)            200         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 5, 10)         0           batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 5, 34)         374         reshape_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 329,040\n",
      "Trainable params: 318,828\n",
      "Non-trainable params: 10,212\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.1), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80044 samples, validate on 19956 samples\n",
      "Epoch 1/2\n",
      "80044/80044 [==============================] - 90s - loss: 0.1720 - acc: 0.9423 - val_loss: 0.2768 - val_acc: 0.9298\n",
      "Epoch 2/2\n",
      "80044/80044 [==============================] - 90s - loss: 0.0573 - acc: 0.9862 - val_loss: 0.5573 - val_acc: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7699176d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 17)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    ps = model.predict(x)\n",
    "    print([''.join([tokens[np.argmax(i)] for i in p]) for p in ps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(4+2)-9']\n"
     ]
    }
   ],
   "source": [
    "predict(x_val[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5-5*1NN'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79860 samples, validate on 20140 samples\n",
      "Epoch 1/1\n",
      "79860/79860 [==============================] - 91s - loss: 0.0753 - acc: 0.9889 - val_loss: 0.2449 - val_acc: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f1d4f2350>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8038 samples, validate on 1962 samples\n",
      "Epoch 1/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.0413 - acc: 0.9878 - val_loss: 1.5496 - val_acc: 0.8078\n",
      "Epoch 2/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.0438 - acc: 0.9870 - val_loss: 0.1985 - val_acc: 0.9568\n",
      "Epoch 3/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.0343 - acc: 0.9897 - val_loss: 0.2150 - val_acc: 0.9503\n",
      "Epoch 4/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.0300 - acc: 0.9909 - val_loss: 0.5148 - val_acc: 0.9139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40ac9e1d10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viiv/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_4 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 1, 30, 90)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Lambda(norm_input, input_shape=(1,30,90)),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(32,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Convolution2D(64,3,3, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    BatchNormalization(),\n",
    "    Dense(700, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Reshape((7, 100)),\n",
    "    TimeDistributed(Dense(17, activation='softmax'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.1), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_4 (Lambda)                (None, 1, 30, 90)     0           lambda_input_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 32, 28, 88)    320         lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 32, 28, 88)    128         convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 32, 26, 86)    9248        batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 32, 26, 86)    128         convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_7 (MaxPooling2D)    (None, 32, 13, 43)    0           batchnormalization_20[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 64, 11, 41)    18496       maxpooling2d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 64, 11, 41)    256         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 64, 9, 39)     36928       batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 64, 9, 39)     256         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_8 (MaxPooling2D)    (None, 64, 4, 19)     0           batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 4864)          0           maxpooling2d_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_23 (BatchNorm (None, 4864)          19456       flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 700)           3405500     batchnormalization_23[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_24 (BatchNorm (None, 700)           2800        dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 700)           0           batchnormalization_24[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)              (None, 7, 100)        0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribut (None, 7, 17)         1717        reshape_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 3,495,233\n",
      "Trainable params: 3,483,721\n",
      "Non-trainable params: 11,512\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79839 samples, validate on 20161 samples\n",
      "Epoch 1/4\n",
      "79839/79839 [==============================] - 94s - loss: 0.7562 - acc: 0.8354 - val_loss: 2.5885 - val_acc: 0.8192\n",
      "Epoch 2/4\n",
      "79839/79839 [==============================] - 94s - loss: 1.7542 - acc: 0.8816 - val_loss: 5.8716 - val_acc: 0.6307\n",
      "Epoch 3/4\n",
      "79839/79839 [==============================] - 94s - loss: 1.9176 - acc: 0.8775 - val_loss: 11.6499 - val_acc: 0.2765\n",
      "Epoch 4/4\n",
      "79839/79839 [==============================] - 94s - loss: 2.0450 - acc: 0.8707 - val_loss: 14.3950 - val_acc: 0.1068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe81f13e150>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79839 samples, validate on 20161 samples\n",
      "Epoch 1/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3963 - acc: 0.8363 - val_loss: 0.8403 - val_acc: 0.8315\n",
      "Epoch 2/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3875 - acc: 0.8404 - val_loss: 3.3851 - val_acc: 0.6475 1s - loss: 0.38\n",
      "Epoch 3/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3835 - acc: 0.8417 - val_loss: 6.5607 - val_acc: 0.4533\n",
      "Epoch 4/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3713 - acc: 0.8450 - val_loss: 2.1141 - val_acc: 0.8101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8371ef290>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79839 samples, validate on 20161 samples\n",
      "Epoch 1/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3769 - acc: 0.8441 - val_loss: 2.9895 - val_acc: 0.6867\n",
      "Epoch 2/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3579 - acc: 0.8507 - val_loss: 3.0588 - val_acc: 0.6825\n",
      "Epoch 3/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3675 - acc: 0.8478 - val_loss: 5.7585 - val_acc: 0.5478\n",
      "Epoch 4/4\n",
      "79839/79839 [==============================] - 89s - loss: 0.3513 - acc: 0.8528 - val_loss: 2.4509 - val_acc: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe875cec850>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8038 samples, validate on 1962 samples\n",
      "Epoch 1/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.5158 - acc: 0.7775 - val_loss: 0.1391 - val_acc: 0.9531\n",
      "Epoch 2/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.5123 - acc: 0.7785 - val_loss: 0.1634 - val_acc: 0.9352\n",
      "Epoch 3/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.5007 - acc: 0.7837 - val_loss: 0.1569 - val_acc: 0.9380\n",
      "Epoch 4/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.4903 - acc: 0.7907 - val_loss: 0.1245 - val_acc: 0.9543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4090ed0390>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8038 samples, validate on 1962 samples\n",
      "Epoch 1/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.4862 - acc: 0.7901 - val_loss: 0.2018 - val_acc: 0.9251\n",
      "Epoch 2/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.4848 - acc: 0.7899 - val_loss: 0.1457 - val_acc: 0.9459\n",
      "Epoch 3/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.4692 - acc: 0.8000 - val_loss: 0.2247 - val_acc: 0.9250\n",
      "Epoch 4/4\n",
      "8038/8038 [==============================] - 9s - loss: 0.4854 - acc: 0.7940 - val_loss: 0.1235 - val_acc: 0.9567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40946b2d90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
